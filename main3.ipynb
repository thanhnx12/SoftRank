{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import DataProcess\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "EPOCHES = 5\n",
    "BATCH_SIZE = 500\n",
    "NUM_OF_LAYERS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    in_features = 136\n",
    "    def __init__(self, params):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1_linear = nn.Linear(self.in_features, params['n1'])\n",
    "        self.layer1_activation = nn.ReLU()\n",
    "        self.layer2_linear = nn.Linear(params['n1'], params['n2'])\n",
    "        self.layer2_activation = nn.ReLU()\n",
    "        self.layer3_linear = nn.Linear(params['n2'], 1)\n",
    "        self.layer3_activation = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.layer1_linear(x)\n",
    "        x = self.layer1_activation(x)\n",
    "        x = self.layer2_linear(x)\n",
    "        x = self.layer2_activation(x)\n",
    "        x = self.layer3_linear(x)\n",
    "        x = self.layer3_activation(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "q = DataProcess.getQuery(\"D:\\\\MSLR-WEB10K\\Fold1\\\\train.txt\",10)\n",
    "test_set = DataProcess.getQuery(\"D:\\\\MSLR-WEB10K\\Fold1\\\\test.txt\",10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "def train_and_evaluate(params):\n",
    "    model = Model(params)\n",
    "    model.layer1_linear.requires_grad_(requires_grad=True)\n",
    "    model.layer2_linear.requires_grad_(requires_grad=True)\n",
    "    model.layer3_linear.requires_grad_(requires_grad=True)\n",
    "    opt = getattr(optim, params['optimizer'])(model.parameters(), lr= params['learning_rate'])\n",
    "    #train\n",
    "    for i in range(100):\n",
    "        PI = q[i].claculate_pi()\n",
    "        P = q[i].prob_all(PI)\n",
    "        dG_ds = q[i].G_derivative_by_score(PI, P)\n",
    "\n",
    "        # model predictions\n",
    "        score = []\n",
    "        dG_dw = []\n",
    "        for param in model.parameters():\n",
    "            dG_dw.append(torch.zeros(param.shape))\n",
    "        for idx,x in enumerate(q[i].documents):\n",
    "            temp = model.forward(x.feature)\n",
    "            score.append(temp)\n",
    "            temp.backward()\n",
    "            for idx1,param in enumerate(model.parameters()):\n",
    "                dG_dw[idx1] += param.grad*dG_ds[idx]/10\n",
    "                param = torch.zeros(param.shape)\n",
    "        for idx,param in enumerate(model.parameters()):\n",
    "            param.grad = dG_dw[idx]\n",
    "        q[i].score = score\n",
    "        # loss\n",
    "\n",
    "        # gradient\n",
    "        # Update Parameters\n",
    "        opt.zero_grad()\n",
    "        opt.step()\n",
    "        model.layer1_linear.weight.grad.zero_()\n",
    "        model.layer1_linear.bias.grad.zero_()\n",
    "        model.layer2_linear.weight.grad.zero_()\n",
    "        model.layer2_linear.bias.grad.zero_()\n",
    "        model.layer3_linear.weight.grad.zero_()\n",
    "        model.layer3_linear.bias.grad.zero_()\n",
    "    #test\n",
    "    res = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(100):\n",
    "            # model predictions\n",
    "            score = []\n",
    "            for x in test_set[i].documents:\n",
    "                temp = model.forward(x.feature)\n",
    "                score.append(temp)\n",
    "            test_set[i].score = score\n",
    "            res.append(test_set[i].NDCG())\n",
    "\n",
    "    print(f\"Mean of Test set NDCG :{np.mean(res)*100} %\")\n",
    "    return np.mean(res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-7, 1e-1),\n",
    "        'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
    "        'n1': trial.suggest_int(\"n_unit\", 50, 70),\n",
    "        'n2': trial.suggest_int(\"n_unit\",50,70)\n",
    "    }\n",
    "\n",
    "    meanNDCG = train_and_evaluate(params)\n",
    "\n",
    "    return meanNDCG"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:12:49,114]\u001B[0m A new study created in memory with name: no-name-e1c9ae15-ecfe-4b3d-a664-de5d82489b37\u001B[0m\n",
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_1984\\4258343626.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-7, 1e-1),\n",
      "\u001B[32m[I 2022-12-29 01:12:58,672]\u001B[0m Trial 0 finished with value: 0.8141693536545379 and parameters: {'learning_rate': 0.00030289256042013166, 'optimizer': 'Adam', 'n_unit': 60}. Best is trial 0 with value: 0.8141693536545379.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8141693536545379 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:13:08,139]\u001B[0m Trial 1 finished with value: 0.833345742360745 and parameters: {'learning_rate': 1.8616864444296277e-06, 'optimizer': 'RMSprop', 'n_unit': 61}. Best is trial 1 with value: 0.833345742360745.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.833345742360745 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:13:18,510]\u001B[0m Trial 2 finished with value: 0.8124454388763508 and parameters: {'learning_rate': 0.024133429242262857, 'optimizer': 'Adam', 'n_unit': 56}. Best is trial 1 with value: 0.833345742360745.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8124454388763508 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:13:27,731]\u001B[0m Trial 3 finished with value: 0.81491832509823 and parameters: {'learning_rate': 0.005254358776641404, 'optimizer': 'Adam', 'n_unit': 58}. Best is trial 1 with value: 0.833345742360745.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.81491832509823 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:13:37,105]\u001B[0m Trial 4 finished with value: 0.7946705284673634 and parameters: {'learning_rate': 0.00016567800572475508, 'optimizer': 'SGD', 'n_unit': 65}. Best is trial 1 with value: 0.833345742360745.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.7946705284673634 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:13:46,824]\u001B[0m Trial 5 finished with value: 0.791019973968684 and parameters: {'learning_rate': 0.0029020664925183868, 'optimizer': 'RMSprop', 'n_unit': 51}. Best is trial 1 with value: 0.833345742360745.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.791019973968684 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:13:56,123]\u001B[0m Trial 6 finished with value: 0.8206524543473183 and parameters: {'learning_rate': 0.06051005334820072, 'optimizer': 'Adam', 'n_unit': 53}. Best is trial 1 with value: 0.833345742360745.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8206524543473183 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:14:05,542]\u001B[0m Trial 7 finished with value: 0.799101240317712 and parameters: {'learning_rate': 0.007736001446549905, 'optimizer': 'Adam', 'n_unit': 52}. Best is trial 1 with value: 0.833345742360745.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.799101240317712 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:14:14,848]\u001B[0m Trial 8 finished with value: 0.7873272102355467 and parameters: {'learning_rate': 0.00045363910550669565, 'optimizer': 'SGD', 'n_unit': 52}. Best is trial 1 with value: 0.833345742360745.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.7873272102355467 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:14:24,094]\u001B[0m Trial 9 finished with value: 0.8106370348765505 and parameters: {'learning_rate': 4.066472273560783e-05, 'optimizer': 'RMSprop', 'n_unit': 64}. Best is trial 1 with value: 0.833345742360745.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8106370348765505 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:14:33,272]\u001B[0m Trial 10 finished with value: 0.841736078220058 and parameters: {'learning_rate': 6.591195057359098e-07, 'optimizer': 'RMSprop', 'n_unit': 69}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.841736078220058 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:14:42,592]\u001B[0m Trial 11 finished with value: 0.8115218181623689 and parameters: {'learning_rate': 3.9090277300794426e-07, 'optimizer': 'RMSprop', 'n_unit': 68}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8115218181623689 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:14:52,223]\u001B[0m Trial 12 finished with value: 0.833080851949549 and parameters: {'learning_rate': 4.2731968890281427e-07, 'optimizer': 'RMSprop', 'n_unit': 70}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.833080851949549 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:15:02,085]\u001B[0m Trial 13 finished with value: 0.8145691300881316 and parameters: {'learning_rate': 4.828429176721745e-06, 'optimizer': 'RMSprop', 'n_unit': 63}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8145691300881316 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:15:12,040]\u001B[0m Trial 14 finished with value: 0.8156282317173098 and parameters: {'learning_rate': 5.038734530042507e-06, 'optimizer': 'RMSprop', 'n_unit': 67}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8156282317173098 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:15:21,244]\u001B[0m Trial 15 finished with value: 0.8107903239469618 and parameters: {'learning_rate': 1.3357703725842462e-07, 'optimizer': 'RMSprop', 'n_unit': 61}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8107903239469618 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:15:30,398]\u001B[0m Trial 16 finished with value: 0.815967237245575 and parameters: {'learning_rate': 4.016073151801102e-06, 'optimizer': 'RMSprop', 'n_unit': 55}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.815967237245575 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:15:39,543]\u001B[0m Trial 17 finished with value: 0.8292362816425828 and parameters: {'learning_rate': 2.4917826694262927e-05, 'optimizer': 'SGD', 'n_unit': 70}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8292362816425828 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:15:48,662]\u001B[0m Trial 18 finished with value: 0.8102354661750311 and parameters: {'learning_rate': 7.419530500860646e-07, 'optimizer': 'RMSprop', 'n_unit': 61}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8102354661750311 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:15:58,250]\u001B[0m Trial 19 finished with value: 0.8166764729724331 and parameters: {'learning_rate': 2.0380376612144293e-06, 'optimizer': 'RMSprop', 'n_unit': 66}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8166764729724331 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:16:07,519]\u001B[0m Trial 20 finished with value: 0.8034594973518145 and parameters: {'learning_rate': 1.1841953236118073e-07, 'optimizer': 'SGD', 'n_unit': 58}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8034594973518145 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:16:17,098]\u001B[0m Trial 21 finished with value: 0.8245236697752988 and parameters: {'learning_rate': 8.191944723190583e-07, 'optimizer': 'RMSprop', 'n_unit': 70}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8245236697752988 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:16:26,342]\u001B[0m Trial 22 finished with value: 0.812469715606299 and parameters: {'learning_rate': 1.2640335943368407e-05, 'optimizer': 'RMSprop', 'n_unit': 68}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.812469715606299 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:16:35,515]\u001B[0m Trial 23 finished with value: 0.8155266731473242 and parameters: {'learning_rate': 5.241141853030843e-07, 'optimizer': 'RMSprop', 'n_unit': 70}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8155266731473242 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:16:44,682]\u001B[0m Trial 24 finished with value: 0.8130749515070357 and parameters: {'learning_rate': 1.5591911250765889e-06, 'optimizer': 'RMSprop', 'n_unit': 63}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8130749515070357 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:16:54,194]\u001B[0m Trial 25 finished with value: 0.8035639770545899 and parameters: {'learning_rate': 2.3998516560973604e-07, 'optimizer': 'RMSprop', 'n_unit': 68}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8035639770545899 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:17:03,770]\u001B[0m Trial 26 finished with value: 0.8105695075514627 and parameters: {'learning_rate': 1.354573750481175e-05, 'optimizer': 'RMSprop', 'n_unit': 66}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8105695075514627 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:17:13,058]\u001B[0m Trial 27 finished with value: 0.7958913819020033 and parameters: {'learning_rate': 1.851495466517629e-06, 'optimizer': 'RMSprop', 'n_unit': 69}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.7958913819020033 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:17:22,435]\u001B[0m Trial 28 finished with value: 0.8354519289150467 and parameters: {'learning_rate': 7.075181851800666e-05, 'optimizer': 'RMSprop', 'n_unit': 65}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.8354519289150467 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-29 01:17:31,573]\u001B[0m Trial 29 finished with value: 0.792123049194 and parameters: {'learning_rate': 0.0006981896481138222, 'optimizer': 'SGD', 'n_unit': 62}. Best is trial 10 with value: 0.841736078220058.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test set NDCG :0.792123049194 %\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 6.591195057359098e-07\n",
      "optimizer: RMSprop\n",
      "n_unit: 69\n"
     ]
    }
   ],
   "source": [
    "best_trial = study.best_trial\n",
    "\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "    number     value             datetime_start          datetime_complete  \\\n0        0  0.814169 2022-12-29 01:12:49.116209 2022-12-29 01:12:58.671573   \n1        1  0.833346 2022-12-29 01:12:58.672574 2022-12-29 01:13:08.139024   \n2        2  0.812445 2022-12-29 01:13:08.140027 2022-12-29 01:13:18.509560   \n3        3  0.814918 2022-12-29 01:13:18.510523 2022-12-29 01:13:27.730852   \n4        4  0.794671 2022-12-29 01:13:27.731793 2022-12-29 01:13:37.104012   \n5        5  0.791020 2022-12-29 01:13:37.105013 2022-12-29 01:13:46.823105   \n6        6  0.820652 2022-12-29 01:13:46.824103 2022-12-29 01:13:56.123332   \n7        7  0.799101 2022-12-29 01:13:56.124346 2022-12-29 01:14:05.541104   \n8        8  0.787327 2022-12-29 01:14:05.542058 2022-12-29 01:14:14.848765   \n9        9  0.810637 2022-12-29 01:14:14.849787 2022-12-29 01:14:24.094967   \n10      10  0.841736 2022-12-29 01:14:24.094967 2022-12-29 01:14:33.271876   \n11      11  0.811522 2022-12-29 01:14:33.273791 2022-12-29 01:14:42.592675   \n12      12  0.833081 2022-12-29 01:14:42.592675 2022-12-29 01:14:52.223979   \n13      13  0.814569 2022-12-29 01:14:52.224937 2022-12-29 01:15:02.085146   \n14      14  0.815628 2022-12-29 01:15:02.086142 2022-12-29 01:15:12.040318   \n15      15  0.810790 2022-12-29 01:15:12.041321 2022-12-29 01:15:21.244345   \n16      16  0.815967 2022-12-29 01:15:21.245849 2022-12-29 01:15:30.397560   \n17      17  0.829236 2022-12-29 01:15:30.398473 2022-12-29 01:15:39.543491   \n18      18  0.810235 2022-12-29 01:15:39.544446 2022-12-29 01:15:48.662796   \n19      19  0.816676 2022-12-29 01:15:48.663795 2022-12-29 01:15:58.250100   \n20      20  0.803459 2022-12-29 01:15:58.252101 2022-12-29 01:16:07.518482   \n21      21  0.824524 2022-12-29 01:16:07.519483 2022-12-29 01:16:17.098130   \n22      22  0.812470 2022-12-29 01:16:17.099134 2022-12-29 01:16:26.342749   \n23      23  0.815527 2022-12-29 01:16:26.343744 2022-12-29 01:16:35.515815   \n24      24  0.813075 2022-12-29 01:16:35.516822 2022-12-29 01:16:44.682060   \n25      25  0.803564 2022-12-29 01:16:44.682558 2022-12-29 01:16:54.194410   \n26      26  0.810570 2022-12-29 01:16:54.194410 2022-12-29 01:17:03.770449   \n27      27  0.795891 2022-12-29 01:17:03.771449 2022-12-29 01:17:13.058659   \n28      28  0.835452 2022-12-29 01:17:13.059606 2022-12-29 01:17:22.435998   \n29      29  0.792123 2022-12-29 01:17:22.436932 2022-12-29 01:17:31.573486   \n\n                 duration  params_learning_rate  params_n_unit  \\\n0  0 days 00:00:09.555364          3.028926e-04             60   \n1  0 days 00:00:09.466450          1.861686e-06             61   \n2  0 days 00:00:10.369533          2.413343e-02             56   \n3  0 days 00:00:09.220329          5.254359e-03             58   \n4  0 days 00:00:09.372219          1.656780e-04             65   \n5  0 days 00:00:09.718092          2.902066e-03             51   \n6  0 days 00:00:09.299229          6.051005e-02             53   \n7  0 days 00:00:09.416758          7.736001e-03             52   \n8  0 days 00:00:09.306707          4.536391e-04             52   \n9  0 days 00:00:09.245180          4.066472e-05             64   \n10 0 days 00:00:09.176909          6.591195e-07             69   \n11 0 days 00:00:09.318884          3.909028e-07             68   \n12 0 days 00:00:09.631304          4.273197e-07             70   \n13 0 days 00:00:09.860209          4.828429e-06             63   \n14 0 days 00:00:09.954176          5.038735e-06             67   \n15 0 days 00:00:09.203024          1.335770e-07             61   \n16 0 days 00:00:09.151711          4.016073e-06             55   \n17 0 days 00:00:09.145018          2.491783e-05             70   \n18 0 days 00:00:09.118350          7.419531e-07             61   \n19 0 days 00:00:09.586305          2.038038e-06             66   \n20 0 days 00:00:09.266381          1.184195e-07             58   \n21 0 days 00:00:09.578647          8.191945e-07             70   \n22 0 days 00:00:09.243615          1.264034e-05             68   \n23 0 days 00:00:09.172071          5.241142e-07             70   \n24 0 days 00:00:09.165238          1.559191e-06             63   \n25 0 days 00:00:09.511852          2.399852e-07             68   \n26 0 days 00:00:09.576039          1.354574e-05             66   \n27 0 days 00:00:09.287210          1.851495e-06             69   \n28 0 days 00:00:09.376392          7.075182e-05             65   \n29 0 days 00:00:09.136554          6.981896e-04             62   \n\n   params_optimizer     state  \n0              Adam  COMPLETE  \n1           RMSprop  COMPLETE  \n2              Adam  COMPLETE  \n3              Adam  COMPLETE  \n4               SGD  COMPLETE  \n5           RMSprop  COMPLETE  \n6              Adam  COMPLETE  \n7              Adam  COMPLETE  \n8               SGD  COMPLETE  \n9           RMSprop  COMPLETE  \n10          RMSprop  COMPLETE  \n11          RMSprop  COMPLETE  \n12          RMSprop  COMPLETE  \n13          RMSprop  COMPLETE  \n14          RMSprop  COMPLETE  \n15          RMSprop  COMPLETE  \n16          RMSprop  COMPLETE  \n17              SGD  COMPLETE  \n18          RMSprop  COMPLETE  \n19          RMSprop  COMPLETE  \n20              SGD  COMPLETE  \n21          RMSprop  COMPLETE  \n22          RMSprop  COMPLETE  \n23          RMSprop  COMPLETE  \n24          RMSprop  COMPLETE  \n25          RMSprop  COMPLETE  \n26          RMSprop  COMPLETE  \n27          RMSprop  COMPLETE  \n28          RMSprop  COMPLETE  \n29              SGD  COMPLETE  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number</th>\n      <th>value</th>\n      <th>datetime_start</th>\n      <th>datetime_complete</th>\n      <th>duration</th>\n      <th>params_learning_rate</th>\n      <th>params_n_unit</th>\n      <th>params_optimizer</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.814169</td>\n      <td>2022-12-29 01:12:49.116209</td>\n      <td>2022-12-29 01:12:58.671573</td>\n      <td>0 days 00:00:09.555364</td>\n      <td>3.028926e-04</td>\n      <td>60</td>\n      <td>Adam</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.833346</td>\n      <td>2022-12-29 01:12:58.672574</td>\n      <td>2022-12-29 01:13:08.139024</td>\n      <td>0 days 00:00:09.466450</td>\n      <td>1.861686e-06</td>\n      <td>61</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.812445</td>\n      <td>2022-12-29 01:13:08.140027</td>\n      <td>2022-12-29 01:13:18.509560</td>\n      <td>0 days 00:00:10.369533</td>\n      <td>2.413343e-02</td>\n      <td>56</td>\n      <td>Adam</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.814918</td>\n      <td>2022-12-29 01:13:18.510523</td>\n      <td>2022-12-29 01:13:27.730852</td>\n      <td>0 days 00:00:09.220329</td>\n      <td>5.254359e-03</td>\n      <td>58</td>\n      <td>Adam</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.794671</td>\n      <td>2022-12-29 01:13:27.731793</td>\n      <td>2022-12-29 01:13:37.104012</td>\n      <td>0 days 00:00:09.372219</td>\n      <td>1.656780e-04</td>\n      <td>65</td>\n      <td>SGD</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>0.791020</td>\n      <td>2022-12-29 01:13:37.105013</td>\n      <td>2022-12-29 01:13:46.823105</td>\n      <td>0 days 00:00:09.718092</td>\n      <td>2.902066e-03</td>\n      <td>51</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>0.820652</td>\n      <td>2022-12-29 01:13:46.824103</td>\n      <td>2022-12-29 01:13:56.123332</td>\n      <td>0 days 00:00:09.299229</td>\n      <td>6.051005e-02</td>\n      <td>53</td>\n      <td>Adam</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>0.799101</td>\n      <td>2022-12-29 01:13:56.124346</td>\n      <td>2022-12-29 01:14:05.541104</td>\n      <td>0 days 00:00:09.416758</td>\n      <td>7.736001e-03</td>\n      <td>52</td>\n      <td>Adam</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>0.787327</td>\n      <td>2022-12-29 01:14:05.542058</td>\n      <td>2022-12-29 01:14:14.848765</td>\n      <td>0 days 00:00:09.306707</td>\n      <td>4.536391e-04</td>\n      <td>52</td>\n      <td>SGD</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>0.810637</td>\n      <td>2022-12-29 01:14:14.849787</td>\n      <td>2022-12-29 01:14:24.094967</td>\n      <td>0 days 00:00:09.245180</td>\n      <td>4.066472e-05</td>\n      <td>64</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>0.841736</td>\n      <td>2022-12-29 01:14:24.094967</td>\n      <td>2022-12-29 01:14:33.271876</td>\n      <td>0 days 00:00:09.176909</td>\n      <td>6.591195e-07</td>\n      <td>69</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>0.811522</td>\n      <td>2022-12-29 01:14:33.273791</td>\n      <td>2022-12-29 01:14:42.592675</td>\n      <td>0 days 00:00:09.318884</td>\n      <td>3.909028e-07</td>\n      <td>68</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>0.833081</td>\n      <td>2022-12-29 01:14:42.592675</td>\n      <td>2022-12-29 01:14:52.223979</td>\n      <td>0 days 00:00:09.631304</td>\n      <td>4.273197e-07</td>\n      <td>70</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>0.814569</td>\n      <td>2022-12-29 01:14:52.224937</td>\n      <td>2022-12-29 01:15:02.085146</td>\n      <td>0 days 00:00:09.860209</td>\n      <td>4.828429e-06</td>\n      <td>63</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>0.815628</td>\n      <td>2022-12-29 01:15:02.086142</td>\n      <td>2022-12-29 01:15:12.040318</td>\n      <td>0 days 00:00:09.954176</td>\n      <td>5.038735e-06</td>\n      <td>67</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>0.810790</td>\n      <td>2022-12-29 01:15:12.041321</td>\n      <td>2022-12-29 01:15:21.244345</td>\n      <td>0 days 00:00:09.203024</td>\n      <td>1.335770e-07</td>\n      <td>61</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>0.815967</td>\n      <td>2022-12-29 01:15:21.245849</td>\n      <td>2022-12-29 01:15:30.397560</td>\n      <td>0 days 00:00:09.151711</td>\n      <td>4.016073e-06</td>\n      <td>55</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>0.829236</td>\n      <td>2022-12-29 01:15:30.398473</td>\n      <td>2022-12-29 01:15:39.543491</td>\n      <td>0 days 00:00:09.145018</td>\n      <td>2.491783e-05</td>\n      <td>70</td>\n      <td>SGD</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>0.810235</td>\n      <td>2022-12-29 01:15:39.544446</td>\n      <td>2022-12-29 01:15:48.662796</td>\n      <td>0 days 00:00:09.118350</td>\n      <td>7.419531e-07</td>\n      <td>61</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>0.816676</td>\n      <td>2022-12-29 01:15:48.663795</td>\n      <td>2022-12-29 01:15:58.250100</td>\n      <td>0 days 00:00:09.586305</td>\n      <td>2.038038e-06</td>\n      <td>66</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>0.803459</td>\n      <td>2022-12-29 01:15:58.252101</td>\n      <td>2022-12-29 01:16:07.518482</td>\n      <td>0 days 00:00:09.266381</td>\n      <td>1.184195e-07</td>\n      <td>58</td>\n      <td>SGD</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>0.824524</td>\n      <td>2022-12-29 01:16:07.519483</td>\n      <td>2022-12-29 01:16:17.098130</td>\n      <td>0 days 00:00:09.578647</td>\n      <td>8.191945e-07</td>\n      <td>70</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>0.812470</td>\n      <td>2022-12-29 01:16:17.099134</td>\n      <td>2022-12-29 01:16:26.342749</td>\n      <td>0 days 00:00:09.243615</td>\n      <td>1.264034e-05</td>\n      <td>68</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>23</td>\n      <td>0.815527</td>\n      <td>2022-12-29 01:16:26.343744</td>\n      <td>2022-12-29 01:16:35.515815</td>\n      <td>0 days 00:00:09.172071</td>\n      <td>5.241142e-07</td>\n      <td>70</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>0.813075</td>\n      <td>2022-12-29 01:16:35.516822</td>\n      <td>2022-12-29 01:16:44.682060</td>\n      <td>0 days 00:00:09.165238</td>\n      <td>1.559191e-06</td>\n      <td>63</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>25</td>\n      <td>0.803564</td>\n      <td>2022-12-29 01:16:44.682558</td>\n      <td>2022-12-29 01:16:54.194410</td>\n      <td>0 days 00:00:09.511852</td>\n      <td>2.399852e-07</td>\n      <td>68</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26</td>\n      <td>0.810570</td>\n      <td>2022-12-29 01:16:54.194410</td>\n      <td>2022-12-29 01:17:03.770449</td>\n      <td>0 days 00:00:09.576039</td>\n      <td>1.354574e-05</td>\n      <td>66</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>0.795891</td>\n      <td>2022-12-29 01:17:03.771449</td>\n      <td>2022-12-29 01:17:13.058659</td>\n      <td>0 days 00:00:09.287210</td>\n      <td>1.851495e-06</td>\n      <td>69</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>28</td>\n      <td>0.835452</td>\n      <td>2022-12-29 01:17:13.059606</td>\n      <td>2022-12-29 01:17:22.435998</td>\n      <td>0 days 00:00:09.376392</td>\n      <td>7.075182e-05</td>\n      <td>65</td>\n      <td>RMSprop</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>29</td>\n      <td>0.792123</td>\n      <td>2022-12-29 01:17:22.436932</td>\n      <td>2022-12-29 01:17:31.573486</td>\n      <td>0 days 00:00:09.136554</td>\n      <td>6.981896e-04</td>\n      <td>62</td>\n      <td>SGD</td>\n      <td>COMPLETE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
